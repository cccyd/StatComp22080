y_test = to_categorical(y_test,num_classes)
img_rows <- c(dim(x_train)[2])
img_cols <- c(dim(x_train)[3])
if(k_image_data_format() == "channels_first"){
x_train = array(data = x_train,dim = c(nrow(x_train),1,img_rows,img_cols))
x_test = array(data = x_test, dim = c(nrow(x_test),1,img_rows,img_cols))
input_shape = c(1,img_rows,img_cols)
} else {
x_train = array(data = x_train,dim = c(nrow(x_train),img_rows,img_cols,1))
x_test = array(data = x_test, dim = c(nrow(x_test),img_rows,img_cols,1))
input_shape = c(img_rows,img_cols,1)
}
model = keras_model_sequential()
model %>%
layer_conv_2d(32,kernel_size = c(3,3),activation = 'relu',
input_shape = input_shape,) %>%
layer_conv_2d(64,kernel_size = c(3,3),activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_dropout(rate = .25) %>%
layer_flatten() %>%
layer_dense(units = 128,activation = 'relu') %>%
layer_dropout(rate = .5) %>%
layer_dense(num_classes,activation = 'softmax') %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'rmsprop')
model %>%
fit(x_train,y_train,
batch_size = batch_size,
epochs = epochs,
validation_split = .2)
model %>%
evaluate(x_test,y_test)
output <- model %>% predict(x_test) %>% k_argmax() %>% as.numeric()
y_test_c <- c()
for (i in 1:dim(y_test)[1]) {
y_test_c[i] <- which.max(y_test[i,])
}
acc <- length(which(output==y_test_c))/length(y_pred)
return(c(acc, output))
}
a=cnn(dataset_mnist(),10,128,1)
a
a[1]
#' @return the accurate rate and prediction results of the trained model on test set
#' @examples
#' \dontrun{
#' num_classes <- 10
#' batch_size <- 128
#' epochs <- 10
#' datasets = dataset_mnist()
#' cnn(datasets,num_classes,batch_size,epochs)
#' }
#' @export
cnn<-function(datasets,num_classes,batch_size,epochs){
c(x_train,y_train,x_test,y_test) %<-% list(datasets$train$x,datasets$train$y,
datasets$test$x,datasets$test$y)
y_train = to_categorical(y_train,num_classes)
y_test = to_categorical(y_test,num_classes)
img_rows <- c(dim(x_train)[2])
img_cols <- c(dim(x_train)[3])
if(k_image_data_format() == "channels_first"){
x_train = array(data = x_train,dim = c(nrow(x_train),1,img_rows,img_cols))
x_test = array(data = x_test, dim = c(nrow(x_test),1,img_rows,img_cols))
input_shape = c(1,img_rows,img_cols)
} else {
x_train = array(data = x_train,dim = c(nrow(x_train),img_rows,img_cols,1))
x_test = array(data = x_test, dim = c(nrow(x_test),img_rows,img_cols,1))
input_shape = c(img_rows,img_cols,1)
}
model = keras_model_sequential()
model %>%
layer_conv_2d(32,kernel_size = c(3,3),activation = 'relu',
input_shape = input_shape,) %>%
layer_conv_2d(64,kernel_size = c(3,3),activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_dropout(rate = .25) %>%
layer_flatten() %>%
layer_dense(units = 128,activation = 'relu') %>%
layer_dropout(rate = .5) %>%
layer_dense(num_classes,activation = 'softmax') %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'rmsprop')
model %>%
fit(x_train,y_train,
batch_size = batch_size,
epochs = epochs,
validation_split = .2)
model %>%
evaluate(x_test,y_test)
output <- model %>% predict(x_test) %>% k_argmax() %>% as.numeric()
y_test_c <- c()
for (i in 1:dim(y_test)[1]) {
y_test_c[i] <- which.max(y_test[i,])
}
acc <- length(which(output==y_test_c))/length(output)
return(c(acc, output))
}
a=cnn(dataset_mnist(),10,128,1)
a[1]
devtools::check()
devtools::build_vignettes()
devtools::build(vignettes=FALSE)
remove.packages("StatComp22080")
install.packages('C:/Users/cccyd/Documents/StatComp22080_1.0.tar.gz',repo=NULL)
library(StatComp22080)
library(keras)
a=cnn(dataset_mnist(),10,128,10)
a[1]
#' @return the accurate rate and prediction results of the trained model on test set
#' @examples
#' \dontrun{
#' num_classes <- 10
#' batch_size <- 128
#' epochs <- 10
#' datasets = dataset_mnist()
#' cnn(datasets,num_classes,batch_size,epochs)
#' }
#' @export
cnn<-function(datasets,num_classes,batch_size,epochs){
c(x_train,y_train,x_test,y_test) %<-% list(datasets$train$x,datasets$train$y,
datasets$test$x,datasets$test$y)
y_train = to_categorical(y_train,num_classes)
y_test = to_categorical(y_test,num_classes)
img_rows <- c(dim(x_train)[2])
img_cols <- c(dim(x_train)[3])
if(k_image_data_format() == "channels_first"){
x_train = array(data = x_train,dim = c(nrow(x_train),1,img_rows,img_cols))
x_test = array(data = x_test, dim = c(nrow(x_test),1,img_rows,img_cols))
input_shape = c(1,img_rows,img_cols)
} else {
x_train = array(data = x_train,dim = c(nrow(x_train),img_rows,img_cols,1))
x_test = array(data = x_test, dim = c(nrow(x_test),img_rows,img_cols,1))
input_shape = c(img_rows,img_cols,1)
}
model = keras_model_sequential()
model %>%
layer_conv_2d(32,kernel_size = c(3,3),activation = 'relu',
input_shape = input_shape,) %>%
layer_conv_2d(64,kernel_size = c(3,3),activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_dropout(rate = .25) %>%
layer_flatten() %>%
layer_dense(units = 128,activation = 'relu') %>%
layer_dropout(rate = .5) %>%
layer_dense(num_classes,activation = 'softmax') %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'rmsprop')
model %>%
fit(x_train,y_train,
batch_size = batch_size,
epochs = epochs,
validation_split = .2)
model %>%
evaluate(x_test,y_test)
output <- model %>% predict(x_test) %>% k_argmax() %>% as.numeric()
y_test_c <- c()
for (i in 1:dim(y_test)[1]) {
y_test_c[i] <- which.max(y_test[i,])
}
acc <- length(which(output==y_test_c))/length(output)
return(c(acc, output))
}
a[1]
a[2]
a[3]
a[4]
b=dataset_mnist()
b$test[1]
b$test
y_test = b$test$y
to_categorical(y_test,10)
a[1]
a[2]
a[3]
a[1:2]
length(which(a[2:length(a)]==b$test$y))/length(a[2:length(a)])
a[1]
1-a[1]
a[2]
a[3]
a[4]
a[-1]
a[1]
#' @return the accurate rate and prediction results of the trained model on test set
#' @examples
#' \dontrun{
#' num_classes <- 10
#' batch_size <- 128
#' epochs <- 10
#' datasets = dataset_mnist()
#' cnn(datasets,num_classes,batch_size,epochs)
#' }
#' @export
cnn<-function(datasets,num_classes,batch_size,epochs){
c(x_train,y_train,x_test,y_test) %<-% list(datasets$train$x,datasets$train$y,
datasets$test$x,datasets$test$y)
y_train = to_categorical(y_train,num_classes)
y_test = to_categorical(y_test,num_classes)
img_rows <- c(dim(x_train)[2])
img_cols <- c(dim(x_train)[3])
if(k_image_data_format() == "channels_first"){
x_train = array(data = x_train,dim = c(nrow(x_train),1,img_rows,img_cols))
x_test = array(data = x_test, dim = c(nrow(x_test),1,img_rows,img_cols))
input_shape = c(1,img_rows,img_cols)
} else {
x_train = array(data = x_train,dim = c(nrow(x_train),img_rows,img_cols,1))
x_test = array(data = x_test, dim = c(nrow(x_test),img_rows,img_cols,1))
input_shape = c(img_rows,img_cols,1)
}
model = keras_model_sequential()
model %>%
layer_conv_2d(32,kernel_size = c(3,3),activation = 'relu',
input_shape = input_shape,) %>%
layer_conv_2d(64,kernel_size = c(3,3),activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_dropout(rate = .25) %>%
layer_flatten() %>%
layer_dense(units = 128,activation = 'relu') %>%
layer_dropout(rate = .5) %>%
layer_dense(num_classes,activation = 'softmax') %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'rmsprop')
model %>%
fit(x_train,y_train,
batch_size = batch_size,
epochs = epochs,
validation_split = .2)
model %>%
evaluate(x_test,y_test)
output <- model %>% predict(x_test) %>% k_argmax() %>% as.numeric()
acc <- length(which(output==datasets$test$y))/length(output)
return(c(acc, output))
}
a=cnn(dataset_mnist(),10,128,1)
a[1]
a[2]
devtools::build_vignettes()
devtools::build(vignettes=FALSE)
remove.packages("StatComp22080")
install.packages('C:/Users/cccyd/Documents/StatComp22080_1.0.tar',repo=NULL)
install.packages('C:/Users/cccyd/Documents/StatComp22080_1.0.tar',repo=NULL)
install.packages('C:/Users/cccyd/Documents/StatComp22080_1.0.tar',repo=NULL)
devtools::build(vignettes=FALSE)
install.packages('C:/Users/cccyd/Documents/StatComp22080_1.0.tar.gz',repo=NULL)
library(keras)
a=cnn(dataset_mnist(),10,128,1)
library(StatComp22080)
a=cnn(dataset_mnist(),10,128,1)
a[1]
as.matrix(c(1,2,3))
library(Rcpp)
data_dir <- getwd()
sourceCpp(paste0("./test.cpp"))
View(acc)
acc(3,as.matrix(c(1,2,3)),as.matrix(c(2,3,4)))
acc(3,as.matrix(c(1,2,3)),as.matrix(c(5,2,3)))
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
rm()
rm(list())
rm(list())
devtools::document()
getwd()
devtools::document()
devtools::check()
devtools::build_vignettes()
devtools::build(vignettes=FALSE)
#' @return the accurate rate and prediction results of the trained model on test set
#' @examples
#' \dontrun{
#' num_classes <- 10
#' batch_size <- 128
#' epochs <- 10
#' datasets = dataset_mnist()
#' dnn(datasets,num_classes,batch_size,epochs)
#' }
#' @export
dnn<-function(datasets,num_classes,batch_size,epochs){
c(x_train,y_train,x_test,y_test) %<-% list(datasets$train$x,datasets$train$y,
datasets$test$x,datasets$test$y)
x_train = array_reshape(x_train, dim = c(nrow(x_train),dim(x_train)[2]*dim(x_train)[3]))
x_train = x_train/255
x_test = array_reshape(x_test,dim = c(nrow(x_test),dim(x_test)[2]*dim(x_test)[3]))
x_test = x_test/255
y_train = to_categorical(y_train,num_classes)
y_test = to_categorical(y_test,num_classes)
DNN = function(num_classes) {
model = keras_model_sequential()
model %>%
layer_dense(units = 100,activation = 'relu',
input_shape = c(NULL,784),name = 'Hidden-1') %>%
layer_dense(units = 100,activation = 'relu',name = 'Hidden-2') %>%
layer_dense(units = 100,activation = 'relu',name = 'Hidden-3') %>%
layer_dense(units = num_classes,activation = 'softmax') %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
}
DNN(num_classes) %>%
fit(x_train,y_train,
epochs = epochs,
batch_size = batch_size,
validation_split = .2)
DNN(num_classes) %>%
evaluate(x_test,y_test,batch_size=batch_size)
output <- DNN(num_classes) %>% predict(x_test) %>% k_argmax() %>% as.numeric()
acc_rio <- length(which(output==datasets$test$y))/length(output)
return(c(acc_rio, output))
}
library(keras)
datasets=dataset_mnist()
dnn(datasets,10,128,1)
a=dnn(datasets,10,128,1)
a[1]
a[2]
a[3]
datasets$test$y[1]
datasets$test$y[2]
datasets$test$y[3]
a=dnn(datasets,10,128,10)
a[1]
a[2]
#' @return the accurate rate and prediction results of the trained model on test set
#' @examples
#' \dontrun{
#' num_classes <- 10
#' batch_size <- 128
#' epochs <- 10
#' datasets = dataset_mnist()
#' dnn(datasets,num_classes,batch_size,epochs)
#' }
#' @export
dnn<-function(datasets,num_classes,batch_size,epochs){
c(x_train,y_train,x_test,y_test) %<-% list(datasets$train$x,datasets$train$y,
datasets$test$x,datasets$test$y)
x_train = array_reshape(x_train, dim = c(nrow(x_train),dim(x_train)[2]*dim(x_train)[3]))
x_train = x_train/255
x_test = array_reshape(x_test,dim = c(nrow(x_test),dim(x_test)[2]*dim(x_test)[3]))
x_test = x_test/255
y_train = to_categorical(y_train,num_classes)
y_test = to_categorical(y_test,num_classes)
DNN = function(num_classes) {
model = keras_model_sequential()
model %>%
layer_dense(units = 100,activation = 'relu',
input_shape = c(NULL,784),name = 'Hidden-1') %>%
layer_dense(units = 100,activation = 'relu',name = 'Hidden-2') %>%
layer_dense(units = 100,activation = 'relu',name = 'Hidden-3') %>%
layer_dense(units = num_classes,activation = 'softmax') %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
}
DNN(num_classes) %>%
fit(x_train,y_train,
epochs = epochs,
batch_size = batch_size,
validation_split = .2)
DNN(num_classes) %>%
evaluate(x_test,y_test,batch_size=batch_size)
output <- DNN(num_classes) %>% predict(x_test,batch_size=batch_size) %>% k_argmax() %>% as.numeric()
acc_rio <- length(which(output==datasets$test$y))/length(output)
return(c(acc_rio, output))
}
a=dnn(datasets,10,128,10)
#' @return the accurate rate and prediction results of the trained model on test set
#' @examples
#' \dontrun{
#' num_classes <- 10
#' batch_size <- 128
#' epochs <- 10
#' datasets = dataset_mnist()
#' dnn(datasets,num_classes,batch_size,epochs)
#' }
#' @export
dnn<-function(datasets,num_classes,batch_size,epochs){
c(x_train,y_train,x_test,y_test) %<-% list(datasets$train$x,datasets$train$y,
datasets$test$x,datasets$test$y)
x_train = array_reshape(x_train, dim = c(nrow(x_train),dim(x_train)[2]*dim(x_train)[3]))
x_train = x_train/255
x_test = array_reshape(x_test,dim = c(nrow(x_test),dim(x_test)[2]*dim(x_test)[3]))
x_test = x_test/255
y_train = to_categorical(y_train,num_classes)
y_test = to_categorical(y_test,num_classes)
DNN = function(num_classes) {
model = keras_model_sequential()
model %>%
layer_dense(units = 100,activation = 'relu',
input_shape = c(NULL,784),name = 'Hidden-1') %>%
layer_dense(units = 50,activation = 'relu',name = 'Hidden-2') %>%
layer_dense(units = num_classes,activation = 'softmax') %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
}
DNN(num_classes) %>%
fit(x_train,y_train,
epochs = epochs,
batch_size = batch_size,
validation_split = .2)
DNN(num_classes) %>%
evaluate(x_test,y_test,batch_size=batch_size)
output <- DNN(num_classes) %>% predict(x_test,batch_size=batch_size) %>% k_argmax() %>% as.numeric()
acc_rio <- length(which(output==datasets$test$y))/length(output)
return(c(acc_rio, output))
}
a=dnn(datasets,10,128,10)
a[1]
a[2]
a[3]
#' @return the accurate rate and prediction results of the trained model on test set
#' @examples
#' \dontrun{
#' num_classes <- 10
#' batch_size <- 128
#' epochs <- 10
#' datasets = dataset_mnist()
#' dnn(datasets,num_classes,batch_size,epochs)
#' }
#' @export
dnn<-function(datasets,num_classes,batch_size,epochs){
c(x_train,y_train,x_test,y_test) %<-% list(datasets$train$x,datasets$train$y,
datasets$test$x,datasets$test$y)
x_train = array_reshape(x_train, dim = c(nrow(x_train),dim(x_train)[2]*dim(x_train)[3]))
x_train = x_train/255
x_test = array_reshape(x_test,dim = c(nrow(x_test),dim(x_test)[2]*dim(x_test)[3]))
x_test = x_test/255
y_train = to_categorical(y_train,num_classes)
y_test = to_categorical(y_test,num_classes)
DNN = function(num_classes) {
model = keras_model_sequential()
model %>%
layer_dense(units = 100,activation = 'relu',
input_shape = c(NULL,784),name = 'Hidden-1') %>%
layer_dense(units = 50,activation = 'relu',name = 'Hidden-2') %>%
layer_dense(units = num_classes,activation = 'softmax') %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
}
DNN(num_classes) %>%
fit(x_train,y_train,
epochs = epochs,
batch_size = batch_size,
validation_split = .2)
DNN(num_classes) %>%
evaluate(x_test,y_test)
output <- DNN(num_classes) %>% predict(x_test) %>% k_argmax() %>% as.numeric()
acc_rio <- length(which(output==datasets$test$y))/length(output)
return(c(acc_rio, output))
}
a=dnn(datasets,10,128,10)
a[1]
#' @return the accurate rate and prediction results of the trained model on test set
#' @examples
#' \dontrun{
#' num_classes <- 10
#' batch_size <- 128
#' epochs <- 10
#' datasets = dataset_mnist()
#' dnn(datasets,num_classes,batch_size,epochs)
#' }
#' @export
dnn<-function(datasets,num_classes,batch_size,epochs){
c(x_train,y_train,x_test,y_test) %<-% list(datasets$train$x,datasets$train$y,
datasets$test$x,datasets$test$y)
x_train = array_reshape(x_train, dim = c(nrow(x_train),dim(x_train)[2]*dim(x_train)[3]))
x_train = x_train/255
x_test = array_reshape(x_test,dim = c(nrow(x_test),dim(x_test)[2]*dim(x_test)[3]))
x_test = x_test/255
y_train = to_categorical(y_train,num_classes)
y_test = to_categorical(y_test,num_classes)
DNN = function(num_classes) {
model = keras_model_sequential()
model %>%
layer_dense(units = 64,activation = 'relu',
input_shape = c(NULL,784),name = 'Hidden-1') %>%
layer_dense(units = 32,activation = 'relu',name = 'Hidden-2') %>%
layer_dense(units = num_classes,activation = 'softmax') %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
}
DNN(num_classes) %>%
fit(x_train,y_train,
epochs = epochs,
batch_size = batch_size,
validation_split = .2)
DNN(num_classes) %>%
evaluate(x_test,y_test)
output <- DNN(num_classes) %>% predict(x_test) %>% k_argmax() %>% as.numeric()
acc_rio <- length(which(output==datasets$test$y))/length(output)
return(c(acc_rio, output))
}
a=dnn(datasets,10,128,10)
devtools::document()
devtools::check()
devtools::build_vignettes()
devtools::build(vignettes=FALSE)
remove.packages("StatComp22080")
git init
